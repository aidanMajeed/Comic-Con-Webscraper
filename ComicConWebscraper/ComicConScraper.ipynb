{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "15a4d41c-d397-4cc8-8d72-d8220a40b0ff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Full List of Actors and their Frequencies:\n",
      "Actor Name\n",
      "Natalie Van Sistine    2\n",
      "Danny Trejo            2\n",
      "Sarah Wiedenheft       2\n",
      "Zach Aguilar           2\n",
      "Megan Shipman          2\n",
      "Ashley Eckstein        2\n",
      "Giancarlo Esposito     2\n",
      "Christopher Sabat      2\n",
      "Ryan Colt Levy         2\n",
      "Rob Paulsen            2\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# URL of the page with guest appearances \n",
    "\n",
    "#2024 guests\n",
    "url1 = 'https://fancons.ca/events/info/21958/fan-expo-canada-2024' \n",
    "#2023 guests\n",
    "url2 = 'https://fancons.ca/events/info/19777/fan-expo-canada-2023'\n",
    "#2022 guests\n",
    "url3 = 'https://fancons.ca/events/info/18101/fan-expo-canada-2022'\n",
    "\n",
    "\n",
    "# Send a request to the 2024 website\n",
    "response = requests.get(url1)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# Send a request to the 2023 Website\n",
    "response2 = requests.get(url2)\n",
    "soup2 = BeautifulSoup(response2.text, 'html.parser')\n",
    "\n",
    "# Send a request to the 2022 Website\n",
    "response3 = requests.get(url3)\n",
    "soup3 = BeautifulSoup(response3.text, 'html.parser')\n",
    "\n",
    "# List to store actor names\n",
    "actor_list = []\n",
    "actor_list_test = []\n",
    "\n",
    "# ------------------------2024----------------------------\n",
    "\n",
    "# Find all <small> elements \n",
    "guests = soup.find_all('li')\n",
    "cancelled = soup.find_all('strike')\n",
    "\n",
    "#2024 guests\n",
    "for guest in guests:\n",
    "    # Find the name and profession\n",
    "    name_tag = guest.find('a')\n",
    "    profession_tag = guest.find('small')\n",
    "    #guests that cancelled their appearance\n",
    "    cancelled_tag = guest.find('strike')\n",
    "    \n",
    "    \n",
    "    # Check if the profession is \"Actor\" and they didnt cancel\n",
    "    if not cancelled_tag and profession_tag and 'Actor' in profession_tag.get_text():\n",
    "        actor_name = name_tag.get_text(strip=True)\n",
    "        actor_list.append(actor_name)\n",
    "        \n",
    "\n",
    "# ------------------------2023----------------------------       \n",
    "        \n",
    "# Find all <small> elements \n",
    "guests_2023 = soup2.find_all('li')\n",
    "cancelled_2023 = soup2.find_all('strike')\n",
    "\n",
    "#2023 guests\n",
    "for guest_2023 in guests_2023:\n",
    "    # Find the name and profession\n",
    "    name_tag_2023 = guest_2023.find('a')\n",
    "    profession_tag_2023 = guest_2023.find('small')\n",
    "    #guests that cancelled their appearance\n",
    "    cancelled_tag_2023 = guest_2023.find('strike')\n",
    "    \n",
    "    \n",
    "    # Check if the profession is \"Actor\" and they didnt cancel\n",
    "    if not cancelled_tag_2023 and profession_tag_2023 and 'Actor' in profession_tag_2023.get_text():\n",
    "        actor_name_2023 = name_tag_2023.get_text(strip=True)\n",
    "        actor_list.append(actor_name_2023)\n",
    "        \n",
    "        \n",
    "# ------------------------2022----------------------------            \n",
    "        \n",
    "# Find all <small> elements \n",
    "guests_2022 = soup3.find_all('li')\n",
    "cancelled_2022 = soup3.find_all('strike')\n",
    "\n",
    "#2022 guests\n",
    "for guest_2022 in guests_2022:\n",
    "    # Find the name and profession\n",
    "    name_tag_2022 = guest_2022.find('a')\n",
    "    profession_tag_2022 = guest_2022.find('small')\n",
    "    #guests that cancelled their appearance\n",
    "    cancelled_tag_2022 = guest_2022.find('strike')\n",
    "    \n",
    "    \n",
    "    # Check if the profession is \"Actor\" and they didnt cancel\n",
    "    if not cancelled_tag_2022 and profession_tag_2022 and 'Actor' in profession_tag_2022.get_text():\n",
    "        actor_name_2022 = name_tag_2022.get_text(strip=True)\n",
    "        actor_list.append(actor_name_2022)\n",
    "\n",
    "\n",
    "# Create a DataFrame and calculate frequency\n",
    "df = pd.DataFrame(actor_list, columns=['Actor Name'])\n",
    "actor_frequency = df['Actor Name'].value_counts()\n",
    "\n",
    "# Show more details\n",
    "print(\"\\nFull List of Actors and their Frequencies:\")\n",
    "print(actor_frequency.head(10))  # Show the top 20 actors with the highest frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bdb58e72-d4b2-4a45-a010-11b2c5126620",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Full List of Actors and their Frequencies:\n",
      "Actor Name\n",
      "Natalie Van Sistine    2\n",
      "Danny Trejo            2\n",
      "Sarah Wiedenheft       2\n",
      "Zach Aguilar           2\n",
      "Megan Shipman          2\n",
      "Ashley Eckstein        2\n",
      "Giancarlo Esposito     2\n",
      "Christopher Sabat      2\n",
      "Ryan Colt Levy         2\n",
      "Rob Paulsen            2\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# URLs of the pages with guest appearances\n",
    "url1 = 'https://fancons.ca/events/info/21958/fan-expo-canada-2024'\n",
    "url2 = 'https://fancons.ca/events/info/19777/fan-expo-canada-2023'\n",
    "url3 = 'https://fancons.ca/events/info/18101/fan-expo-canada-2022'\n",
    "\n",
    "# Function to fetch and parse actor names from a given URL\n",
    "def fetch_actors(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    actor_list = []\n",
    "\n",
    "    # Find all <li> elements\n",
    "    guests = soup.find_all('li')\n",
    "\n",
    "    for guest in guests:\n",
    "        name_tag = guest.find('a')\n",
    "        profession_tag = guest.find('small')\n",
    "        cancelled_tag = guest.find('strike')\n",
    "\n",
    "        if not cancelled_tag and profession_tag and 'Actor' in profession_tag.get_text():\n",
    "            actor_name = name_tag.get_text(strip=True)\n",
    "            actor_list.append(actor_name)\n",
    "\n",
    "    return actor_list\n",
    "\n",
    "# Collect actors from all years\n",
    "actor_list_2024 = fetch_actors(url1)\n",
    "actor_list_2023 = fetch_actors(url2)\n",
    "actor_list_2022 = fetch_actors(url3)\n",
    "\n",
    "# Combine all lists\n",
    "actor_list = actor_list_2024 + actor_list_2023 + actor_list_2022\n",
    "\n",
    "# Create a DataFrame and calculate frequency\n",
    "df = pd.DataFrame(actor_list, columns=['Actor Name'])\n",
    "actor_frequency = df['Actor Name'].value_counts()\n",
    "\n",
    "\n",
    "\n",
    "# Show more details\n",
    "print(\"\\nFull List of Actors and their Frequencies:\")\n",
    "print(actor_frequency.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e3adbd-43ea-4a0f-89ce-924c8f64b8cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
